# 👁️ פרויקט גמר במדעי הנתונים

## שם הפרויקט: **FractureNet: מערכת דו-שלבית לזיהוי ואיתור שברים בתצלומי רנטגן**

---

## 👩‍🎓 שמות הסטודנטים

- **עומרי שלזינגר**
  ת"ז: 322985672
  📧 omri.shlezinger@gmail.com
  📞 055-2288789

## התמחות: מדעי הנתונים

## מאשרת הפרויקט: אושרית שטוסל

---

## 🔍 מה קיים היום

- **MURA:** מאגר מידע פומבי ענק של תצלומי רנטגן (גפיים) מסטנפורד, משמש לבנצ'מרק של מודלי סיווג.
- **מודלי סיווג תמונות:** ארכיטקטורות בסיס (Backbones) כמו **ResNet**, **VGG**, ו-**EfficientNet** המשמשות לסיווג תמונות (רלוונטי לשלב 1).
- **מודלי זיהוי עצמים:** ארכיטקטורות כמו **YOLO** (You Only Look Once) ו-**Faster R-CNN** המשמשות לאיתור אובייקטים (רלוונטי לשלב 2).
- **מודלי סגמנטציה:** ארכיטקטורות כמו **U-Net**, המתמחות בדימות רפואי ומאפשרות איתור מדויק ברמת הפיקסל.

---

## 🎯 מטרת הפרויקט

לפתח מערכת AI דו-שלבית מבוססת למידה עמוקה לניתוח תצלומי רנטגן:

1.  **שלב 1 (Router Model):** לאמן מודל סיווג (Classifier) שיקבל תמונת רנטגן ויזהה לאיזה אזור בגוף היא שייכת (גפיים, אגן, חזה או גולגולת).
2.  **שלב 2 (Expert Models):** להפנות את התמונה למודל "מומחה" ייעודי (אחד מארבעה) שאומן ספציפית על אותו אזור גוף, במטרה לזהות (Object Detection) האם קיים שבר, ובמידה וכן – לאתר את מיקומו המדויק.
3.  **תוצר סופי:** פיתוח ממשק Web פשוט שיאפשר העלאת תמונת רנטגן ויחזיר למשתמש את התמונה עם סימון (עיגול או ריבוע) סביב אזור השבר, במידה וזוהה.

---

## 🧩 תיאור הפרויקט

### תחום הבעיה

- ראייה ממוחשבת (Computer Vision)
- דימות רפואי (Medical Imaging)
- למידה עמוקה (Deep Learning)
- פיתוח מערכות AI (AI Pipeline Development)

### הפתרון המוצע

המערכת מורכבת מ-Pipeline של מודלים:

- **משימה עיקרית (שלב 1 - סיווג):**

  - **קלט (Input):** תמונת רנטגן (למשל, 512x512, Grayscale).
  - **פלט (Output):** וקטור הסתברויות (Softmax) עבור 4 קטגוריות:
    - Class 0: חזה (Chest)
    - Class 1: אגן (Pelvis)
    - Class 2: גפיים (Limbs)
    - Class 3: גולגולת (Skull)

- **משימה משנית (שלב 2 - זיהוי עצמים):**

  - המודל משלב 1 "מנתב" את התמונה לאחד מ-4 מודלים ייעודיים.
  - **קלט (Input):** אותה תמונת רנטגן.
  - **פלט (Output):** רשימת קואורדינטות (Bounding Boxes) וציון ביטחון (Confidence Score) עבור כל שבר שזוהה בתמונה. `[class_id, x_center, y_center, width, height, confidence]`.

- **ממשק משתמש:**
  - אפליקציית Web (מבוססת Flask / FastAPI) המריצה את ה-Pipeline ומציגה את התוצאה הסופית.

### 🧱 מטרות ותוצרי מפתח

1.  **תוצר 1 – מודל הניתוב:**
    מודל `BodyPartClassifier` מאומן (למשל, Fine-Tuned ResNet50) המסוגל לסווג תמונות רנטגן לארבעת האזורים בדיוק גבוה.

2.  **תוצר 2 – מודלי המומחה:**
    ארבעה מודלי Object Detection מאומנים (למשל, YOLOv8), כאשר כל מודל מתמחה בזיהוי שברים באזור גוף ספציפי (חזה, אגן, גפיים, גולגולת).

3.  **תוצר 3 – אפליקציית Web:**
    ממשק Web פונקציונלי המאפשר העלאת תמונה, מריץ את כל שרשרת החיזוי (שלב 1 -> שלב 2) ומציג את התמונה המקורית עם סימון אדום סביב השברים שזוהו.

### 🧬 מקורות דאטה

| שלב               | קטגוריה      | מקור                                         | תיאור                                                                    |
| :---------------- | :----------- | :------------------------------------------- | :----------------------------------------------------------------------- |
| **שלב 1 (סיווג)** | כל 4 האזורים | מאגרים ציבוריים (MURA, ChestX-ray14, Kaggle) | איסוף ואיחוד דאטהסטים. **התווית** (Labeling) פשוטה יחסית (סוג האזור).    |
| **שלב 2 (זיהוי)** | גפיים        | **MURA Dataset**                             | מאגר ענק, אך התיעוד הוא ברמת התמונה (שבור/לא שבור) ולא ברמת המיקום.      |
| **שלב 2 (זיהוי)** | כללי         | **GRAZPEDWRI-1 / פרויקטים מ-Kaggle**         | מאגרים קטנים יותר אך עם **תיעוד מלא (Bounding Boxes)** של מיקומי השברים. |

**אתגר מרכזי:** השגת דאטה _עם תיוג מיקום_ (Bounding Boxes) עבור שלב 2. סביר להניח שיהיה צורך להשתמש במאגרים קטנים יותר וממוקדים, או לבצע תיוג ידני חלקי באמצעות כלים כמו **LabelImg**.

### 💾 ייצוג נתונים

- **קלט:** תמונות יומרו לגודל אחיד (למשל, `512x512x1`) ויעברו נורמליזציה (סקיילינג 0-1).
- **אוגמנטציה:** שימוש נרחב באוגמנטציות (סיבוב, הזזה, שינוי בהירות/ניגודיות) כדי להגדיל את כמות הדאטה ולמנוע Overfitting.
- **תוויות (שלב 1):** וקטור One-Hot (למשל, `[0, 0, 1, 0]` עבור "גפיים").
- **תוויות (שלב 2):** קבצי טקסט המכילים את מיקומי ה-Bounding Box בפורמט YOLO (`[class, x, y, w, h]`).

### 🧠 ארכיטקטורת רשת הנוירונים

1.  **שלב 1 (Router Model):**

    - **Transfer Learning** על בסיס ארכיטקטורת **ResNet50** (או **EfficientNetV2**).
    - החלפת השכבה העליונה בשכבת `Dense` עם 4 יציאות + `Softmax`.

2.  **שלב 2 (Expert Models):**
    - ארכיטקטורת זיהוי עצמים (Object Detection) מהירה ומדויקת, כגון **YOLOv8**.
    - (אופציה מתקדמת): מודל סגמנטציה כגון **U-Net** לזיהוי מדויק ברמת הפיקסל.

### 📊 הערכה ואימות

- **מדדים (שלב 1 – סיווג):**

  - Accuracy
  - Precision, Recall, F1-score
  - **Confusion Matrix** (קריטי להבנת טעויות הניתוב)

- **מדדים (שלב 2 – זיהוי):**
  - **mAP (mean Average Precision)**: המדד הסטנדרטי להערכת מודלי זיהוי עצמים.
  - **IoU (Intersection over Union)**: לבדיקת מידת החפיפה בין הניבוי למיקום האמיתי.

### 🔎 פרשנות ורלוונטיות

- **שלב 1 (פרשנות):**

  - שימוש בטכניקות כמו **Grad-CAM** או **LIME** כדי להציג "מפת חום" (Heatmap) על גבי התמונה, המראה על אילו פיקסלים המודל "הסתכל" כדי להחליט שזו תמונת חזה.

- **שלב 2 (פרשנות):**
  - התוצר עצמו (ה-Bounding Box) הוא בר-פרשנות מיידית.
  - הצגת **ציון הביטחון (Confidence Score)** של המודל ליד כל זיהוי.

## ☁️ תשתיות וסביבת עבודה

#### סביבת עבודה

הפרויקט יפותח ב**פייתון** בסביבת **Jupyter Notebook** על גבי **Google Colab** (לניצול GPU).
שימוש בספריות עיקריות: **PyTorch** (או TensorFlow/Keras), **OpenCV**, **Scikit-learn**.
הקוד, הדאטה והמחברות ינוהלו ב־**Git Repository** ייעודי.

#### תשתיות

המערכת תיפרס כאפליקציית Web באמצעות:

- **Backend:** שרת **Flask** או **FastAPI** שיטעין את המודלים המאומנים (קובצי `.pt` או `.h5`) ויחשוף API לחיזוי.
- **Frontend:** ממשק HTML/CSS/JavaScript בסיסי שיאפשר העלאת קובץ תמונה וקבלת התוצאה.
- **פריסה (Deployment):** ניתן לפרוס על גבי שירות ענן (AWS, GCP, Heroku) או מקומית.
